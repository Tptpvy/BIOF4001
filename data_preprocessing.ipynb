{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b336ea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# define folder paths\n",
    "PLT_DATA_PATH = \"./Sepsis_plt/plt/PLT_TRUE/reduction_rate/\"\n",
    "PLT_LIST_PATH = \"./Sepsis_plt/Sepsis plt/\"\n",
    "HN_FILE_PATH = \"./Sepsis_plt/Sepsis plt/plt_ASEhn_ALL.txt\"\n",
    "DEMO_DATA_PATH = \"./Sepsis_plt/demographic/\" # not 25 ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c04d9703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_SIC_HN(): # merge SIC HN lists\n",
    "    files = glob.glob(PLT_LIST_PATH + \"plt_ASEhn_p*.txt\")\n",
    "    if not files:\n",
    "        print(f\"No files found in {PLT_LIST_PATH}.\")\n",
    "        return\n",
    "    \n",
    "    all_lines = []\n",
    "    for file in files:\n",
    "        try:\n",
    "            with open(file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                all_lines.extend(lines)\n",
    "                print(f\"Read {len(lines)} lines from {file}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "    \n",
    "    output_file = os.path.join(PLT_LIST_PATH, \"plt_ASEhn_ALL.txt\")\n",
    "    with open(output_file, 'w') as f:\n",
    "        for line in all_lines:\n",
    "            f.write(line)\n",
    "    print(f\"Merged {len(files)} files into {output_file} with {len(all_lines)} total lines.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1c12802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_plt_lab(test): # merge ASE patients lab data by year\n",
    "    LAB_DATA_PATH = \"./Sepsis_plt/All sepsis/allSepsis/\" # not 25 ver\n",
    "    OUTPUT_PATH = f\"./Sepsis_plt/by_year/{test}/\"\n",
    "    os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "    # match file names according to lab test\n",
    "    match test:\n",
    "        case \"plt\":\n",
    "            LAB_DATA_PATH = PLT_DATA_PATH\n",
    "            pattern = \"*_Sepsis_PresumedInfection_Bili_Plt_\"\n",
    "        case \"crea\":\n",
    "            pattern = \"*_Sepsis_PresumedInfection_Crea_\"\n",
    "        case \"bili\":\n",
    "            pattern = \"*_Sepsis_PresumedInfection_Bili_Plt_\"\n",
    "        case \"resp\":\n",
    "            pattern = \"*_Sepsis_PresumedInfection_Procedure_\"\n",
    "        case \"lact\":\n",
    "            pattern = \"*_Sepsis_PresumedInfection_Lactate_\"\n",
    "    \n",
    "    mdfs = []\n",
    "    for year in range(2001, 2024):\n",
    "        print(f\"Processing year: {year}\")\n",
    "        files = glob.glob(LAB_DATA_PATH + f\"{pattern}{year}*.csv\")\n",
    "        if not files:\n",
    "            print(f\"No files found for year {year} with pattern {pattern}\")\n",
    "            continue\n",
    "        print(f\"Found {len(files)} files for year {year}\")\n",
    "        dfs = []\n",
    "        for file in files:\n",
    "            try:\n",
    "                df = pd.read_csv(file)\n",
    "                if 'Year' not in df.columns: # add year column for identification\n",
    "                    df['Year'] = year\n",
    "                dfs.append(df)\n",
    "                mdfs.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file}: {e}\")\n",
    "                continue\n",
    "        if dfs:\n",
    "            combined_df = pd.concat(dfs, ignore_index=True)\n",
    "            output_file = os.path.join(OUTPUT_PATH, f\"{test}_{year}.csv\")\n",
    "            combined_df.to_csv(output_file, index=False)\n",
    "            print(f\"Saved combined data for year {year} to {output_file}, {len(combined_df)} total rows\")\n",
    "\n",
    "    master_df = pd.concat(mdfs, ignore_index=True) # combine all years\n",
    "    output_file = os.path.join(OUTPUT_PATH, f\"{test}_all.csv\")\n",
    "    master_df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved master data to {output_file}, {len(master_df)} total rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3ed2df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_SIC(test): # filter SIC patients lab data\n",
    "    LAB_DATA_PATH = f\"./Sepsis_plt/by_year/{test}/{test}_all.csv\"\n",
    "    OUTPUT_PATH = f\"./Sepsis_plt/by_year/{test}/\"\n",
    "    os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "    if not os.path.exists(LAB_DATA_PATH):\n",
    "        print(f\"Lab data file {LAB_DATA_PATH} does not exist.\")\n",
    "        return\n",
    "    if not os.path.exists(HN_FILE_PATH):\n",
    "        print(f\"HN list {HN_FILE_PATH} does not exist.\")\n",
    "        return\n",
    "    \n",
    "    try: # retrieve target HN numbers\n",
    "        with open(HN_FILE_PATH, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            target_HN_numbers = set()\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                if line and \",\" in line:\n",
    "                    HN_number = line.split(\",\")[-1].strip()\n",
    "                    if HN_number:\n",
    "                        target_HN_numbers.add(HN_number)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading HN file: {e}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(LAB_DATA_PATH)\n",
    "        original_rows = len(df)\n",
    "        if 'HN Number' in df.columns:\n",
    "            df['HN Number'] = df['HN Number'].astype(str)\n",
    "            filtered_df = df[df['HN Number'].isin(target_HN_numbers)]\n",
    "            output_file = os.path.join(OUTPUT_PATH, f\"{test}_SIC_all.csv\")\n",
    "            filtered_df.to_csv(output_file, index=False)\n",
    "            filtered_rows = len(filtered_df)\n",
    "            print(f\"Filtered data saved to {output_file}, {filtered_rows} rows out of {original_rows} original rows.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading lab data file: {e}\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b873334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_demographic(): # merge demographic data by year\n",
    "    OUTPUT_PATH = \"./Sepsis_plt/by_year/demographic/\"\n",
    "    os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "    pattern = \"*_presumedInfection_Demographic_\"\n",
    "    mdfs = []\n",
    "    for year in range(2001, 2024):\n",
    "        print(f\"Processing year: {year}\")\n",
    "        files = glob.glob(DEMO_DATA_PATH + f\"{pattern}{year}*.csv\")\n",
    "        if not files:\n",
    "            print(f\"No files found for year {year} with pattern {pattern}\")\n",
    "            continue\n",
    "        print(f\"Found {len(files)} files for year {year}\")\n",
    "        dfs = []\n",
    "        for file in files:\n",
    "            try:\n",
    "                df = pd.read_csv(file)\n",
    "                if 'Year' not in df.columns: # add year column for identification\n",
    "                    df['Year'] = year\n",
    "                if '28_day_mortality' not in df.columns: # calculate 28-day mortality\n",
    "                    df['Admission_Date'] = pd.to_datetime(df['Admission Date (yyyy-mm-dd)'], errors='coerce')\n",
    "                    df['Death_Date'] = pd.to_datetime(df['Date of Registered Death'], errors='coerce')\n",
    "                    mask = df['Admission_Date'].notna() & df['Death_Date'].notna()\n",
    "                    df.loc[mask, 'Days_To_Death'] = (df.loc[mask, 'Death_Date'] - df.loc[mask, 'Admission_Date']).dt.days\n",
    "                    df['28_day_mortality'] = (df['Days_To_Death'] <= 28) & (df['Days_To_Death'] >= 0)\n",
    "                    df['28_day_mortality'] = df['28_day_mortality'].fillna(False)\n",
    "                    df = df.drop(['Admission_Date', 'Death_Date', 'Days_To_Death'], axis=1, errors='ignore')\n",
    "                dfs.append(df)\n",
    "                mdfs.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file}: {e}\")\n",
    "                continue\n",
    "        if dfs:\n",
    "            combined_df = pd.concat(dfs, ignore_index=True)\n",
    "            output_file = os.path.join(OUTPUT_PATH, f\"demographic_{year}.csv\")\n",
    "            combined_df.to_csv(output_file, index=False)\n",
    "            print(f\"Saved combined data for year {year} to {output_file}, {len(combined_df)} total rows\")\n",
    "\n",
    "    master_df = pd.concat(mdfs, ignore_index=True) # combine all years\n",
    "    output_file = os.path.join(OUTPUT_PATH, f\"demographic_all.csv\")\n",
    "    master_df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved master data to {output_file}, {len(master_df)} total rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f756a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_demographic_SIC(): # filter SIC patients demographic data\n",
    "    DEMO_DATA_PATH = \"./Sepsis_plt/by_year/demographic/demographic_all.csv\"\n",
    "    OUTPUT_PATH = \"./Sepsis_plt/by_year/demographic/\"\n",
    "    os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "    \n",
    "    if not os.path.exists(HN_FILE_PATH):\n",
    "        print(f\"HN list {HN_FILE_PATH} does not exist.\")\n",
    "        return\n",
    "    if not os.path.exists(DEMO_DATA_PATH):\n",
    "        print(f\"Demographic data file do not exist.\")\n",
    "        return\n",
    "    \n",
    "    try: # retrieve target HN numbers\n",
    "        with open(HN_FILE_PATH, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            target_HN_numbers = set()\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                if line and \",\" in line:\n",
    "                    HN_number = line.split(\",\")[-1].strip()\n",
    "                    if HN_number:\n",
    "                        target_HN_numbers.add(HN_number)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading HN file: {e}\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(DEMO_DATA_PATH)\n",
    "        original_rows = len(df)\n",
    "        if 'HN Number' in df.columns:\n",
    "            df['HN Number'] = df['HN Number'].astype(str)\n",
    "            filtered_df = df[df['HN Number'].isin(target_HN_numbers)]\n",
    "            output_file = os.path.join(OUTPUT_PATH, f\"demographic_SIC_all.csv\")\n",
    "            filtered_df.to_csv(output_file, index=False)\n",
    "            filtered_rows = len(filtered_df)\n",
    "            print(f\"Filtered data saved to {output_file}, {filtered_rows} rows out of {original_rows} original rows.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading demographic data file: {e}\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45c46130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique_HN(file): # count unique HN numbers in a file\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        if 'HN Number' in df.columns:\n",
    "            unique_HNs = df['HN Number'].nunique()\n",
    "            print(f\"File {file} contains {unique_HNs} unique HN Numbers.\")\n",
    "        else:\n",
    "            print(f\"'HN Number' column not found in {file}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9026e4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CDARS_list(file): # create CDARS request list\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        if 'HN Number' in df.columns and 'Institution (IPAS)' in df.columns:\n",
    "            cdars_list = df[['HN Number', 'Institution (IPAS)']].drop_duplicates() # get unique HN and Institution pairs\n",
    "            output_file = \"./Sepsis_plt/CDARS_request_list.txt\"\n",
    "            with open(output_file, 'w') as f:\n",
    "                for _, row in cdars_list.iterrows():\n",
    "                    f.write(f\"{row['Institution (IPAS)']},{row['HN Number']}\\n\")\n",
    "            print(f\"CDARS request list saved to {output_file}\")\n",
    "        else:\n",
    "            print(f\"'HN Number' or 'Institution (IPAS)' column not found in {file}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63f7e205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 5000 lines from ./Sepsis_plt/Sepsis plt\\plt_ASEhn_p1.txt.\n",
      "Read 5000 lines from ./Sepsis_plt/Sepsis plt\\plt_ASEhn_p10.txt.\n",
      "Read 5000 lines from ./Sepsis_plt/Sepsis plt\\plt_ASEhn_p11.txt.\n",
      "Read 5000 lines from ./Sepsis_plt/Sepsis plt\\plt_ASEhn_p12.txt.\n",
      "Read 5000 lines from ./Sepsis_plt/Sepsis plt\\plt_ASEhn_p13.txt.\n",
      "Read 3722 lines from ./Sepsis_plt/Sepsis plt\\plt_ASEhn_p14.txt.\n",
      "Read 5000 lines from ./Sepsis_plt/Sepsis plt\\plt_ASEhn_p2.txt.\n",
      "Read 5000 lines from ./Sepsis_plt/Sepsis plt\\plt_ASEhn_p3.txt.\n",
      "Read 5000 lines from ./Sepsis_plt/Sepsis plt\\plt_ASEhn_p4.txt.\n",
      "Read 5000 lines from ./Sepsis_plt/Sepsis plt\\plt_ASEhn_p5.txt.\n",
      "Read 5000 lines from ./Sepsis_plt/Sepsis plt\\plt_ASEhn_p6.txt.\n",
      "Read 5000 lines from ./Sepsis_plt/Sepsis plt\\plt_ASEhn_p7.txt.\n",
      "Read 5000 lines from ./Sepsis_plt/Sepsis plt\\plt_ASEhn_p8.txt.\n",
      "Read 5000 lines from ./Sepsis_plt/Sepsis plt\\plt_ASEhn_p9.txt.\n",
      "Merged 14 files into ./Sepsis_plt/Sepsis plt/plt_ASEhn_ALL.txt with 68722 total lines.\n"
     ]
    }
   ],
   "source": [
    "merge_SIC_HN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0ee90a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing year: 2001\n",
      "Found 4 files for year 2001\n",
      "Saved combined data for year 2001 to ./Sepsis_plt/by_year/crea/crea_2001.csv, 651 total rows\n",
      "Processing year: 2002\n",
      "Found 6 files for year 2002\n",
      "Saved combined data for year 2002 to ./Sepsis_plt/by_year/crea/crea_2002.csv, 862 total rows\n",
      "Processing year: 2003\n",
      "Found 12 files for year 2003\n",
      "Saved combined data for year 2003 to ./Sepsis_plt/by_year/crea/crea_2003.csv, 2779 total rows\n",
      "Processing year: 2004\n",
      "Found 14 files for year 2004\n",
      "Saved combined data for year 2004 to ./Sepsis_plt/by_year/crea/crea_2004.csv, 3345 total rows\n",
      "Processing year: 2005\n",
      "Found 15 files for year 2005\n",
      "Saved combined data for year 2005 to ./Sepsis_plt/by_year/crea/crea_2005.csv, 3648 total rows\n",
      "Processing year: 2006\n",
      "Found 14 files for year 2006\n",
      "Saved combined data for year 2006 to ./Sepsis_plt/by_year/crea/crea_2006.csv, 3554 total rows\n",
      "Processing year: 2007\n",
      "Found 14 files for year 2007\n",
      "Saved combined data for year 2007 to ./Sepsis_plt/by_year/crea/crea_2007.csv, 3379 total rows\n",
      "Processing year: 2008\n",
      "Found 16 files for year 2008\n",
      "Saved combined data for year 2008 to ./Sepsis_plt/by_year/crea/crea_2008.csv, 3788 total rows\n",
      "Processing year: 2009\n",
      "Found 15 files for year 2009\n",
      "Saved combined data for year 2009 to ./Sepsis_plt/by_year/crea/crea_2009.csv, 3398 total rows\n",
      "Processing year: 2010\n",
      "Found 12 files for year 2010\n",
      "Saved combined data for year 2010 to ./Sepsis_plt/by_year/crea/crea_2010.csv, 2651 total rows\n",
      "Processing year: 2011\n",
      "Found 13 files for year 2011\n",
      "Saved combined data for year 2011 to ./Sepsis_plt/by_year/crea/crea_2011.csv, 3208 total rows\n",
      "Processing year: 2012\n",
      "Found 16 files for year 2012\n",
      "Saved combined data for year 2012 to ./Sepsis_plt/by_year/crea/crea_2012.csv, 3875 total rows\n",
      "Processing year: 2013\n",
      "Found 16 files for year 2013\n",
      "Saved combined data for year 2013 to ./Sepsis_plt/by_year/crea/crea_2013.csv, 3971 total rows\n",
      "Processing year: 2014\n",
      "Found 23 files for year 2014\n",
      "Saved combined data for year 2014 to ./Sepsis_plt/by_year/crea/crea_2014.csv, 6258 total rows\n",
      "Processing year: 2015\n",
      "Found 24 files for year 2015\n",
      "Saved combined data for year 2015 to ./Sepsis_plt/by_year/crea/crea_2015.csv, 6178 total rows\n",
      "Processing year: 2016\n",
      "Found 21 files for year 2016\n",
      "Saved combined data for year 2016 to ./Sepsis_plt/by_year/crea/crea_2016.csv, 5730 total rows\n",
      "Processing year: 2017\n",
      "Found 17 files for year 2017\n",
      "Saved combined data for year 2017 to ./Sepsis_plt/by_year/crea/crea_2017.csv, 4650 total rows\n",
      "Processing year: 2018\n",
      "Found 20 files for year 2018\n",
      "Saved combined data for year 2018 to ./Sepsis_plt/by_year/crea/crea_2018.csv, 5439 total rows\n",
      "Processing year: 2019\n",
      "Found 34 files for year 2019\n",
      "Saved combined data for year 2019 to ./Sepsis_plt/by_year/crea/crea_2019.csv, 8900 total rows\n",
      "Processing year: 2020\n",
      "Found 29 files for year 2020\n",
      "Saved combined data for year 2020 to ./Sepsis_plt/by_year/crea/crea_2020.csv, 8197 total rows\n",
      "Processing year: 2021\n",
      "Found 31 files for year 2021\n",
      "Saved combined data for year 2021 to ./Sepsis_plt/by_year/crea/crea_2021.csv, 9127 total rows\n",
      "Processing year: 2022\n",
      "Found 27 files for year 2022\n",
      "Saved combined data for year 2022 to ./Sepsis_plt/by_year/crea/crea_2022.csv, 9156 total rows\n",
      "Processing year: 2023\n",
      "Found 31 files for year 2023\n",
      "Saved combined data for year 2023 to ./Sepsis_plt/by_year/crea/crea_2023.csv, 8649 total rows\n",
      "Saved master data to ./Sepsis_plt/by_year/crea/crea_all.csv, 111393 total rows\n",
      "Filtered data saved to ./Sepsis_plt/by_year/crea/crea_SIC_all.csv, 25173 rows out of 111393 original rows.\n"
     ]
    }
   ],
   "source": [
    "test = \"crea\" # lab data type: plt, crea, bili, resp, lact\n",
    "merge_plt_lab(test)\n",
    "filter_SIC(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b13a7e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing year: 2001\n",
      "Found 4 files for year 2001\n",
      "Saved combined data for year 2001 to ./Sepsis_plt/by_year/demographic/demographic_2001.csv, 62826 total rows\n",
      "Processing year: 2002\n",
      "Found 6 files for year 2002\n",
      "Saved combined data for year 2002 to ./Sepsis_plt/by_year/demographic/demographic_2002.csv, 82941 total rows\n",
      "Processing year: 2003\n",
      "Found 12 files for year 2003\n",
      "Saved combined data for year 2003 to ./Sepsis_plt/by_year/demographic/demographic_2003.csv, 181091 total rows\n",
      "Processing year: 2004\n",
      "Found 14 files for year 2004\n",
      "Saved combined data for year 2004 to ./Sepsis_plt/by_year/demographic/demographic_2004.csv, 199944 total rows\n",
      "Processing year: 2005\n",
      "Found 15 files for year 2005\n",
      "Saved combined data for year 2005 to ./Sepsis_plt/by_year/demographic/demographic_2005.csv, 215447 total rows\n",
      "Processing year: 2006\n",
      "Found 14 files for year 2006\n",
      "Saved combined data for year 2006 to ./Sepsis_plt/by_year/demographic/demographic_2006.csv, 211911 total rows\n",
      "Processing year: 2007\n",
      "Found 14 files for year 2007\n",
      "Saved combined data for year 2007 to ./Sepsis_plt/by_year/demographic/demographic_2007.csv, 223236 total rows\n",
      "Processing year: 2008\n",
      "Found 16 files for year 2008\n",
      "Saved combined data for year 2008 to ./Sepsis_plt/by_year/demographic/demographic_2008.csv, 315621 total rows\n",
      "Processing year: 2009\n",
      "Found 15 files for year 2009\n",
      "Saved combined data for year 2009 to ./Sepsis_plt/by_year/demographic/demographic_2009.csv, 408745 total rows\n",
      "Processing year: 2010\n",
      "Found 12 files for year 2010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vincent Yeung\\AppData\\Local\\Temp\\ipykernel_30740\\3248818326.py:16: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined data for year 2010 to ./Sepsis_plt/by_year/demographic/demographic_2010.csv, 362484 total rows\n",
      "Processing year: 2011\n",
      "Found 13 files for year 2011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vincent Yeung\\AppData\\Local\\Temp\\ipykernel_30740\\3248818326.py:16: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined data for year 2011 to ./Sepsis_plt/by_year/demographic/demographic_2011.csv, 383853 total rows\n",
      "Processing year: 2012\n",
      "Found 16 files for year 2012\n",
      "Saved combined data for year 2012 to ./Sepsis_plt/by_year/demographic/demographic_2012.csv, 451674 total rows\n",
      "Processing year: 2013\n",
      "Found 16 files for year 2013\n",
      "Saved combined data for year 2013 to ./Sepsis_plt/by_year/demographic/demographic_2013.csv, 409495 total rows\n",
      "Processing year: 2014\n",
      "Found 23 files for year 2014\n",
      "Saved combined data for year 2014 to ./Sepsis_plt/by_year/demographic/demographic_2014.csv, 572146 total rows\n",
      "Processing year: 2015\n",
      "Found 24 files for year 2015\n",
      "Saved combined data for year 2015 to ./Sepsis_plt/by_year/demographic/demographic_2015.csv, 575807 total rows\n",
      "Processing year: 2016\n",
      "Found 21 files for year 2016\n",
      "Saved combined data for year 2016 to ./Sepsis_plt/by_year/demographic/demographic_2016.csv, 508916 total rows\n",
      "Processing year: 2017\n",
      "Found 17 files for year 2017\n",
      "Saved combined data for year 2017 to ./Sepsis_plt/by_year/demographic/demographic_2017.csv, 401792 total rows\n",
      "Processing year: 2018\n",
      "Found 20 files for year 2018\n",
      "Saved combined data for year 2018 to ./Sepsis_plt/by_year/demographic/demographic_2018.csv, 451944 total rows\n",
      "Processing year: 2019\n",
      "Found 34 files for year 2019\n",
      "Saved combined data for year 2019 to ./Sepsis_plt/by_year/demographic/demographic_2019.csv, 733215 total rows\n",
      "Processing year: 2020\n",
      "Found 29 files for year 2020\n",
      "Saved combined data for year 2020 to ./Sepsis_plt/by_year/demographic/demographic_2020.csv, 652867 total rows\n",
      "Processing year: 2021\n",
      "Found 31 files for year 2021\n",
      "Saved combined data for year 2021 to ./Sepsis_plt/by_year/demographic/demographic_2021.csv, 690889 total rows\n",
      "Processing year: 2022\n",
      "Found 21 files for year 2022\n",
      "Saved combined data for year 2022 to ./Sepsis_plt/by_year/demographic/demographic_2022.csv, 480293 total rows\n",
      "Processing year: 2023\n",
      "Found 31 files for year 2023\n",
      "Saved combined data for year 2023 to ./Sepsis_plt/by_year/demographic/demographic_2023.csv, 653620 total rows\n",
      "Saved master data to ./Sepsis_plt/by_year/demographic/demographic_all.csv, 9230757 total rows\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'filter_demographic_SIC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m merge_demographic()\n\u001b[1;32m----> 2\u001b[0m filter_demographic_SIC()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filter_demographic_SIC' is not defined"
     ]
    }
   ],
   "source": [
    "merge_demographic()\n",
    "filter_demographic_SIC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c53dee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./Sepsis_plt/by_year/crea/crea_all.csv contains 111393 unique HN Numbers.\n",
      "File ./Sepsis_plt/by_year/demographic/demographic_all.csv contains 2024914 unique HN Numbers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2024914"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests = [\"plt\", \"crea\", \"bili\", \"resp\", \"lact\"] # count unique HN numbers for lab data files\n",
    "for test in tests:\n",
    "    file = f\"./Sepsis_plt/by_year/{test}/{test}_all.csv\"\n",
    "    count_unique_HN(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c26bf900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDARS request list saved to ./Sepsis_plt/CDARS_request_list.txt\n"
     ]
    }
   ],
   "source": [
    "file = \"./Sepsis_plt/by_year/crea/crea_all.csv\"\n",
    "create_CDARS_list(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
